{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.features.build_features import get_train_test\n",
    "from src.models.find_model import check_model\n",
    "from sklearn.metrics import confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"../data/processed/heart_processed\"\n",
    "X_train, X_test, y_train, y_test = get_train_test(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and select model for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we tries to predict if person has bigger chance for heart attact or not, so we would like to maximalize the recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SVM Model - linear / poly / rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.85 \t| 0.9\n",
      "recall\t\t 0.94 \t| 0.88\n",
      "f1-score\t 0.89 \t| 0.89\n",
      "accuracy\t 0.88 \t| 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_linear = SVC(kernel='linear', C=0.4)\n",
    "check_model(svc_linear, *get_train_test(df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.9 \t| 0.91\n",
      "recall\t\t 0.9 \t| 0.91\n",
      "f1-score\t 0.9 \t| 0.91\n",
      "accuracy\t 0.89 \t| 0.9\n"
     ]
    }
   ],
   "source": [
    "svc_poly = SVC(kernel='poly', C=0.4, degree=2, gamma='scale')\n",
    "check_model(svc_poly, *get_train_test(df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.89 \t| 0.93\n",
      "recall\t\t 0.9 \t| 0.88\n",
      "f1-score\t 0.9 \t| 0.9\n",
      "accuracy\t 0.88 \t| 0.9\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel=\"rbf\", C=0.4, gamma='scale')\n",
    "check_model(svc_rbf, *get_train_test(df_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.87 \t| 0.9\n",
      "recall\t\t 0.91 \t| 0.88\n",
      "f1-score\t 0.89 \t| 0.89\n",
      "accuracy\t 0.88 \t| 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", penalty=\"l2\", C=1.0)\n",
    "check_model(log_reg, *get_train_test(df_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.84 \t| 0.85\n",
      "recall\t\t 0.96 \t| 0.91\n",
      "f1-score\t 0.9 \t| 0.88\n",
      "accuracy\t 0.88 \t| 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_cls = DecisionTreeClassifier(random_state=42, max_depth=4, min_samples_split=4)\n",
    "check_model(dt_cls, *get_train_test(df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.85 \t| 0.88\n",
      "recall\t\t 0.92 \t| 0.91\n",
      "f1-score\t 0.88 \t| 0.89\n",
      "accuracy\t 0.87 \t| 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_cls = RandomForestClassifier(\n",
    "    random_state=42, max_depth=3, min_samples_split=4, \n",
    "    n_estimators=100, n_jobs=-1\n",
    "    )\n",
    "check_model(rf_cls, *get_train_test(df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat__thall_2     0.146694\n",
       "cat__cp_0        0.127342\n",
       "cat__caa_0       0.092234\n",
       "num__oldpeak     0.087697\n",
       "num__thalachh    0.082875\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature importance in random forest\n",
    "rf_feature_importance = pd.DataFrame(rf_cls.feature_importances_, index = X_test.columns)\n",
    "rf_feature_importance[0].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. AdaBoost & Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.84 \t| 0.91\n",
      "recall\t\t 0.89 \t| 0.91\n",
      "f1-score\t 0.86 \t| 0.91\n",
      "accuracy\t 0.84 \t| 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_cls = AdaBoostClassifier(random_state=42, n_estimators=100, learning_rate=0.01)\n",
    "check_model(ada_cls, *get_train_test(df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat__thall_2    0.32\n",
       "cat__caa_0      0.29\n",
       "cat__cp_0       0.21\n",
       "num__oldpeak    0.08\n",
       "cat__exng_0     0.07\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature importance in AdaBoost\n",
    "ada_feature_importance = pd.DataFrame(ada_cls.feature_importances_, index = X_test.columns)\n",
    "ada_feature_importance[0].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t train\t| test\n",
      "precision\t 0.84 \t| 0.88\n",
      "recall\t\t 0.92 \t| 0.91\n",
      "f1-score\t 0.87 \t| 0.89\n",
      "accuracy\t 0.86 \t| 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_cls = GradientBoostingClassifier(\n",
    "    random_state=42, \n",
    "    loss=\"log_loss\", \n",
    "    n_estimators=100, \n",
    "    max_depth=2, \n",
    "    min_samples_split=8, \n",
    "    max_features=1.0,\n",
    "    learning_rate=0.01)\n",
    "check_model(gb_cls, *get_train_test(df_path))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c255ba86a6d0075ceff98e91438cda1cc57aee8ebb35fc649c7209093bee4b9f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
